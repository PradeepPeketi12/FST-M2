root@3d5323054955:/user/root# cd
root@3d5323054955:~# cd
root@3d5323054955:~# cd /
root@3d5323054955:/# cd user/root/input
bash: cd: user/root/input: No such file or directory
root@3d5323054955:/# clear
root@3d5323054955:/# hdfs dfs -mkdir /user/root/input
mkdir: `/user/root/input': File exists
root@3d5323054955:/# hdfs dfs -ls /user/root/input
Found 36 items
-rw-r--r--   1 root supergroup       9213 2021-08-23 10:44 /user/root/input/capacity-scheduler.xml
-rw-r--r--   1 root supergroup       1335 2021-08-23 10:44 /user/root/input/configuration.xsl
-rw-r--r--   1 root supergroup       2567 2021-08-23 10:44 /user/root/input/container-executor.cfg
-rw-r--r--   1 root supergroup        155 2021-08-23 10:44 /user/root/input/core-site.xml
-rw-r--r--   1 root supergroup        154 2021-08-23 10:44 /user/root/input/core-site.xml.template
-rw-r--r--   1 root supergroup      67671 2023-06-24 06:47 /user/root/input/episodeIV_dialouges.txt
-rw-r--r--   1 root supergroup      43658 2023-06-24 06:47 /user/root/input/episodeVI_dialouges.txt
-rw-r--r--   1 root supergroup      49891 2023-06-24 06:47 /user/root/input/episodeV_dialouges.txt
-rw-r--r--   1 root supergroup       3999 2021-08-23 10:44 /user/root/input/hadoop-env.cmd
-rw-r--r--   1 root supergroup      16794 2021-08-23 10:44 /user/root/input/hadoop-env.sh
-rw-r--r--   1 root supergroup       3321 2021-08-23 10:44 /user/root/input/hadoop-metrics2.properties
-rw-r--r--   1 root supergroup      11765 2021-08-23 10:44 /user/root/input/hadoop-policy.xml
-rw-r--r--   1 root supergroup       3414 2021-08-23 10:44 /user/root/input/hadoop-user-functions.sh.example
-rw-r--r--   1 root supergroup        683 2021-08-23 10:44 /user/root/input/hdfs-rbf-site.xml
-rw-r--r--   1 root supergroup        354 2021-08-23 10:44 /user/root/input/hdfs-site.xml
-rw-r--r--   1 root supergroup       1484 2021-08-23 10:44 /user/root/input/httpfs-env.sh
-rw-r--r--   1 root supergroup       1657 2021-08-23 10:44 /user/root/input/httpfs-log4j.properties
-rw-r--r--   1 root supergroup        620 2021-08-23 10:44 /user/root/input/httpfs-site.xml
-rw-r--r--   1 root supergroup       3518 2021-08-23 10:44 /user/root/input/kms-acls.xml
-rw-r--r--   1 root supergroup       1351 2021-08-23 10:44 /user/root/input/kms-env.sh
-rw-r--r--   1 root supergroup       1860 2021-08-23 10:44 /user/root/input/kms-log4j.properties
-rw-r--r--   1 root supergroup        682 2021-08-23 10:44 /user/root/input/kms-site.xml
-rw-r--r--   1 root supergroup      13700 2021-08-23 10:44 /user/root/input/log4j.properties
-rw-r--r--   1 root supergroup        951 2021-08-23 10:44 /user/root/input/mapred-env.cmd
-rw-r--r--   1 root supergroup       1764 2021-08-23 10:44 /user/root/input/mapred-env.sh
-rw-r--r--   1 root supergroup       4113 2021-08-23 10:44 /user/root/input/mapred-queues.xml.template
-rw-r--r--   1 root supergroup        138 2021-08-23 10:44 /user/root/input/mapred-site.xml
drwxr-xr-x   - root supergroup          0 2021-08-23 10:44 /user/root/input/shellprofile.d
-rw-r--r--   1 root supergroup       2316 2021-08-23 10:44 /user/root/input/ssl-client.xml.example
-rw-r--r--   1 root supergroup       2697 2021-08-23 10:44 /user/root/input/ssl-server.xml.example
-rw-r--r--   1 root supergroup       2681 2021-08-23 10:44 /user/root/input/user_ec_policies.xml.template
-rw-r--r--   1 root supergroup         10 2021-08-23 10:44 /user/root/input/workers
-rw-r--r--   1 root supergroup       2250 2021-08-23 10:44 /user/root/input/yarn-env.cmd
-rw-r--r--   1 root supergroup       6329 2021-08-23 10:44 /user/root/input/yarn-env.sh
-rw-r--r--   1 root supergroup       1525 2021-08-23 10:44 /user/root/input/yarn-site.xml
-rw-r--r--   1 root supergroup       2591 2021-08-23 10:44 /user/root/input/yarnservice-log4j.properties
root@3d5323054955:/# hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.1/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = 13f9ac38-2d70-47c8-9296-adf6c84c41d7

Logging initialized using configuration in jar:file:/usr/local/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive Session ID = abe22e2d-21c6-4377-98cd-d03001d25396
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive> show databases;
OK
default
office
Time taken: 0.666 seconds, Fetched: 2 row(s)
hive> use office;
OK
Time taken: 0.029 seconds
hive> CREATE TABLE episodeIV (name STRING, line STRING)
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' TBLPROPERTIES ("skip.header.line.count"="2");
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. AlreadyExistsException(message:Table hive.office.episodeIV already exists)
hive> drop table episodeIV
    > ;
OK
Time taken: 0.501 seconds
hive> CREATE TABLE episodeIV (name STRING, line STRING)
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' TBLPROPERTIES ("skip.header.line.count"="2");
OK
Time taken: 0.152 seconds
hive> LOAD DATA LOCAL INPATH '/user/root/input/episodeIV_dialouges.txt' INTO TABLE episodeIV;
FAILED: SemanticException Line 1:23 Invalid path ''/user/root/input/episodeIV_dialouges.txt'': No files matching path file:/user/root/input/episodeIV_dialouges.txt
hive> LOAD DATA LOCAL INPATH 'user/root/input/episodeIV_dialouges.txt' INTO TABLE episodeIV;
FAILED: SemanticException Line 1:23 Invalid path ''user/root/input/episodeIV_dialouges.txt'': No files matching path file:/user/root/input/episodeIV_dialouges.txt
hive> LOAD DATA LOCAL INPATH hdfs dfs 'user/root/input/episodeIV_dialouges.txt' INTO TABLE episodeIV;
MismatchedTokenException(24!=379)
        at org.antlr.runtime.BaseRecognizer.recoverFromMismatchedToken(BaseRecognizer.java:617)
        at org.antlr.runtime.BaseRecognizer.match(BaseRecognizer.java:115)
        at org.apache.hadoop.hive.ql.parse.HiveParser.loadStatement(HiveParser.java:2661)
        at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:2410)
        at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1420)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:220)
        at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:74)
        at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:67)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:616)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1826)
        at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1773)
        at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1768)
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:126)
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:214)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:239)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:188)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:402)
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:821)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:759)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:683)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
FAILED: ParseException line 1:23 mismatched input 'hdfs' expecting StringLiteral near 'INPATH' in load statement
hive> exit;
root@3d5323054955:/# cd user/root
root@3d5323054955:/user/root# ls
root@3d5323054955:/user/root# ls -l
total 0
root@3d5323054955:/user/root# cd
root@3d5323054955:~# cd/
bash: cd/: No such file or directory
root@3d5323054955:~# cd /
root@3d5323054955:/# ls
bin        dev                      etc    media         pig_1687408441700.log  root  sys   var
boot       episodeIV_dialouges.txt  home   metastore_db  pig_1687408516100.log  run   tmp
count.pig  episodeVI_dialouges.txt  lib    mnt           pig_1687408947086.log  sbin  user
derby.log  episodeV_dialouges.txt   lib64  opt           proc                   srv   usr
root@3d5323054955:/# cd home
root@3d5323054955:/home# ls
csv.File.csv             episodeVI_dialouges.txt  file01.txt  salesCSV.pig  txtFile.txt
episodeIV_dialouges.txt  episodeV_dialouges.txt   sales.csv   textData      wordcount.pig
root@3d5323054955:/home# cd
root@3d5323054955:~# cd /
root@3d5323054955:/# hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.1/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = cce5f84e-4037-4449-a2dc-b390230e9916

Logging initialized using configuration in jar:file:/usr/local/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive Session ID = 5e97aa47-c24e-49af-94f4-5ffa65d65075
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive> show databases;
OK
default
office
Time taken: 0.676 seconds, Fetched: 2 row(s)
hive> use office;
OK
Time taken: 0.025 seconds
hive> LOAD DATA LOCAL INPATH '/home/input/episodeIV_dialouges.txt' INTO TABLE episodeIV;
FAILED: SemanticException Line 1:23 Invalid path ''/home/input/episodeIV_dialouges.txt'': No files matching path file:/home/input/episodeIV_dialouges.txt
hive> LOAD DATA LOCAL INPATH '/home/episodeIV_dialouges.txt' INTO TABLE episodeIV;
Loading data to table office.episodeiv
OK
Time taken: 1.38 seconds
hive> SELECT name, COUNT(name) AS no_of_lines from episodeIV GROUP BY name ORDER BY no_of_lines DESC;
Query ID = root_20230624072133_3d636214-1f21-4ae0-98a3-3140aa00c66b
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1687589903529_0001, Tracking URL = http://3d5323054955:8088/proxy/application_1687589903529_0001/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1687589903529_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-06-24 07:21:46,208 Stage-1 map = 0%,  reduce = 0%
2023-06-24 07:21:50,380 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.23 sec
2023-06-24 07:21:55,541 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.35 sec
MapReduce Total cumulative CPU time: 4 seconds 350 msec
Ended Job = job_1687589903529_0001
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1687589903529_0002, Tracking URL = http://3d5323054955:8088/proxy/application_1687589903529_0002/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1687589903529_0002
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2023-06-24 07:22:08,145 Stage-2 map = 0%,  reduce = 0%
2023-06-24 07:22:14,400 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.82 sec
2023-06-24 07:22:18,525 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 4.16 sec
MapReduce Total cumulative CPU time: 4 seconds 160 msec
Ended Job = job_1687589903529_0002
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.35 sec   HDFS Read: 79808 HDFS Write: 2015 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.16 sec   HDFS Read: 9535 HDFS Write: 1753 SUCCESS
Total MapReduce CPU Time Spent: 8 seconds 510 msec
OK
LUKE    253
HAN     152
THREEPIO        119
BEN     76
LEIA    57
VADER   41
RED LEADER      36
BIGGS   34
TARKIN  28
OWEN    25
TROOPER 19
GOLD LEADER     14
WEDGE   14
OFFICER 11
RED TEN 7
GOLD FIVE       7
DODONNA 6
DEATH STAR INTERCOM VOICE       6
INTERCOM VOICE  6
GREEDO  6
FIRST TROOPER   6
AUNT BERU       6
BEN'S VOICE     6
JABBA   6
HUMAN   4
TAGGE   4
MOTTI   4
VOICE   3
SECOND TROOPER  3
MASSASSI INTERCOM VOICE 3
COMMANDER       3
BARTENDER       3
CAMIE   2
CHIEF   2
WILLARD 2
FIXER   2
GANTRY OFFICER  2
GOLD TWO        2
IMPERIAL OFFICER        2
WOMAN   1
WINGMAN'S VOICE 1
WINGMAN 1
VOICE OVER DEATH STAR INTERCOM  1
TROOPER VOICE   1
TECHNICIAN      1
SECOND OFFICER  1
RED TEN'S VOICE 1
RED SEVEN       1
RED NINE'S VOICE        1
RED NINE        1
RED LEADER'S VOICE      1
RED ELEVEN      1
REBEL OFFICER   1
PORKINS 1
OFFICER CASS    1
MAN'S VOICE     1
LUKE'S VOICE    1
HAN'S VOICE     1
FIRST OFFICER   1
DEAK    1
CREATURE        1
CONTROL OFFICER 1
CHIEF PILOT     1
CAPTAIN 1
BERU    1
BASE VOICE      1
ASTRO-OFFICER   1
Time taken: 45.96 seconds, Fetched: 67 row(s)
hive> CREATE TABLE episodeV (name STRING, line STRING)
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' TBLPROPERTIES ("skip.header.line.count"="2");
OK
Time taken: 0.214 seconds
hive> LOAD DATA LOCAL INPATH '/root/episodeV_dialouges.txt' INTO TABLE episodeV;
Loading data to table office.episodev
OK
Time taken: 0.593 seconds
hive> SELECT name, COUNT(name) AS no_of_lines from episodeV GROUP BY name ORDER BY no_of_lines DESC;
Query ID = root_20230624072342_4fac339b-2ca9-4ab5-b7b3-1a27fc27b640
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1687589903529_0003, Tracking URL = http://3d5323054955:8088/proxy/application_1687589903529_0003/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1687589903529_0003
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-06-24 07:23:49,200 Stage-1 map = 0%,  reduce = 0%
2023-06-24 07:23:55,423 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.0 sec
2023-06-24 07:24:00,584 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.71 sec
MapReduce Total cumulative CPU time: 5 seconds 710 msec
Ended Job = job_1687589903529_0003
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1687589903529_0004, Tracking URL = http://3d5323054955:8088/proxy/application_1687589903529_0004/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1687589903529_0004
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2023-06-24 07:24:12,613 Stage-2 map = 0%,  reduce = 0%
2023-06-24 07:24:17,782 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.07 sec
2023-06-24 07:24:22,976 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 4.99 sec
MapReduce Total cumulative CPU time: 4 seconds 990 msec
Ended Job = job_1687589903529_0004
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.71 sec   HDFS Read: 62012 HDFS Write: 1530 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.99 sec   HDFS Read: 9046 HDFS Write: 1333 SUCCESS
Total MapReduce CPU Time Spent: 10 seconds 700 msec
OK
HAN     182
LUKE    128
LEIA    114
THREEPIO        92
LANDO   61
VADER   56
YODA    36
PIETT   23
CREATURE        21
RIEEKAN 13
BEN     11
WEDGE   8
VEERS   7
DECK OFFICER    7
ZEV     6
OZZEL   5
NEEDA   5
EMPEROR 5
BOBA FETT       4
JANSON  4
DACK    4
BEN'S VOICE     4
ANNOUNCER       3
CONTROLLER      3
TRENCH OFFICER  3
DERLIN  3
IMPERIAL OFFICER        2
MEDICAL DROID   2
LIEUTENANT      2
SENIOR CONTROLLER       2
INTERCOM VOICE  2
TRACKING OFFICER        2
COMMUNICATIONS OFFICER  2
HOBBIE  1
HEAD CONTROLLER 1
STRANGE VOICE   1
FIRST CONTROLLER        1
SECOND OFFICER  1
MAN'S VOICE     1
ASSISTANT OFFICER       1
OFFICER 1
SECOND CONTROLLER       1
PILOT   1
REBEL FIGHTER   1
CAPTAIN 1
PILOTS  1
REBEL CAPTAIN   1
WOMAN CONTROLLER        1
IMPERIAL SOLDIER        1
SECOND THREEPIO 1
Time taken: 41.894 seconds, Fetched: 50 row(s)
hive> CREATE TABLE episodeVI (name STRING, line STRING)
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' TBLPROPERTIES ("skip.header.line.count"="2");
OK
Time taken: 0.064 seconds
hive> LOAD DATA LOCAL INPATH '/home/episodeVI_dialouges.txt' INTO TABLE episodeVI;
Loading data to table office.episodevi
OK
Time taken: 0.166 seconds
hive> SELECT name, COUNT(name) AS no_of_lines from episodeVI GROUP BY name ORDER BY no_of_lines DESC;
Query ID = root_20230624072631_fdeb2116-2882-4e3a-bc3f-2e9e473932d8
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1687589903529_0005, Tracking URL = http://3d5323054955:8088/proxy/application_1687589903529_0005/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1687589903529_0005
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-06-24 07:26:39,128 Stage-1 map = 0%,  reduce = 0%
2023-06-24 07:26:44,278 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.88 sec
2023-06-24 07:26:49,448 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.75 sec
MapReduce Total cumulative CPU time: 5 seconds 750 msec
Ended Job = job_1687589903529_0005
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1687589903529_0006, Tracking URL = http://3d5323054955:8088/proxy/application_1687589903529_0006/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1687589903529_0006
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2023-06-24 07:27:02,627 Stage-2 map = 0%,  reduce = 0%
2023-06-24 07:27:09,977 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.45 sec
2023-06-24 07:27:15,214 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 6.14 sec
MapReduce Total cumulative CPU time: 6 seconds 140 msec
Ended Job = job_1687589903529_0006
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.75 sec   HDFS Read: 55795 HDFS Write: 4792 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 6.14 sec   HDFS Read: 12312 HDFS Write: 4253 SUCCESS
Total MapReduce CPU Time Spent: 11 seconds 890 msec
OK
HAN     104
LUKE    100
THREEPIO        84
LEIA    51
VADER   37
LANDO   35
EMPEROR 31
JABBA (in Huttese subtitled)    15
BEN     14
ACKBAR  11
WEDGE   10
YODA    10
COMMANDER       7
PIETT   6
JERJERROD       6
BOUSHH  5
BIB     5
STORMTROOPER    5
NINEDENINE      5
JABBA   4
REBEL PILOT     3
HAN (cont)      3
SCOUT #1        2
GENERAL MADINE  2
MON MOTHMA      2
CONTROLLER (over radio) 2
SHUTTLE CAPTAIN 2
CONTROLLER      2
ACKBAR (VO)     2
GUARD   2
BOUSHH (in Ubese subtitled)     2
YODA (tickled, chuckles)        1
YODA (shakes his head)  1
YODA (gathering all his strength)       1
Y-WING PILOT    1
WEDGE (VO)      1
WALKER PILOT #1 1
VOICE (OS)      1
VADER (turning to face him)     1
VADER (skeptical)       1
VADER (indicating lightsaber)   1
VADER (bows)    1
VADER (after a beat)    1
VADER (a whisper)       1
THREEPIO (to Wicket)    1
THREEPIO (to Artoo)     1
THREEPIO (still shaken) 1
THREEPIO (instantly)    1
THREEPIO (disappearing) 1
THREEPIO (cont) 1
STRANGE VOICE   1
STORMTROOPER (OS)       1
SECOND COMMANDER        1
SCOUT #l        1
SCOUT #2        1
SCOUT   1
RED TWO 1
RED THREE       1
RED LEADER (VO) 1
PILOT VOICE (HAN)(filtered)     1
PILOT #2        1
PILOT   1
PIETT (surprised)       1
PIETT (into comlink)    1
OPERATOR        1
OOLA    1
OFFICER 1
NINEDENINE (to a Gamorrean guard)       1
NAVIGATOR       1
MON MOTHMA (cont)       1
LURE    1
LUKE (with sadness)     1
LUKE (turning away, derisive)   1
LUKE (to Leia)  1
LUKE (shrugging it off) 1
LUKE (sarcastic)        1
LUKE (pointing to the controls) 1
LUKE (moving to his ship)       1
LUKE (indicating the one ahead) 1
LUKE (hesitant) 1
LUKE (groans)   1
LUKE (cont)     1
LUKE (concerned)        1
LEIA (to Han)   1
LEIA (softly)   1
LEIA (over comlink)     1
LEIA (into comlink)     1
LANDO (to himself)      1
LANDO (smiling) 1
LANDO (over comlink)    1
LANDO (into comlink)    1
LANDO (desperately)     1
JERJERROD (aghast)      1
JABBA (cont Huttese subtitled)  1
HAN/PILOT (VO)  1
HAN and LUKE    1
HAN (with self-confident grin)  1
HAN (whispering to himself)     1
HAN (turning to Luke)   1
HAN (to Luke)   1
HAN (to Leia)   1
HAN (smiles)    1
HAN (sighs)     1
HAN (sarcastic) 1
HAN (over comlink)      1
HAN (loses his temper)  1
HAN (looks at him warmly)       1
HAN (grins)     1
HAN (gravely)   1
HAN (chuckles)  1
HAN (blinking)  1
HAN (angry)     1
HAN (OS)        1
GREEN LEADER    1
GRAY LEADER     1
EMPEROR (very cool)     1
EMPEROR (to Vader)      1
EMPEROR (to Luke)       1
EMPEROR (no surprise)   1
EMPEROR (laughs)        1
EMPEROR (laughing)      1
EMPEROR (cont)  1
EMPEROR (angry) 1
DEATH STAR CONTROLLER(filtered VO)      1
CONTROLLER (filtered)   1
CONTROL ROOM COMMANDER  1
BUNKER COMMANDER        1
BIB (in Huttese subtitled)      1
BEN (grinning at Luke's indignation)    1
BEN (continuing his narrative)  1
BEN (attempting to give solace with his words)  1
BEN (OS)        1
ANAKIN (very weak)      1
ANAKIN  1
ACKBAR (cont)   1
LEIA (alarmed)  1
Time taken: 45.527 seconds, Fetched: 136 row(s)
hive>